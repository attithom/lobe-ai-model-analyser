{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a37d453",
   "metadata": {},
   "source": [
    "# Model Analysis\n",
    "\n",
    "Use this Jupyter Notebook to analyse the performance of exported Lobe.ai models.\n",
    "\n",
    "1. Export your Lobe.ai model as TensorFlow for Python\n",
    "2. Paste the contents of your exported model (labels.txt, saved_model.pb, signature.json, variables and example) to the LobeModel/ directory.\n",
    "3. Paste your structured labelled test images into TEST1/ (Further test directories can be added and the script will process them all automatically)\n",
    "4. Run this notebook."
   ]
  },
  {
   "cell_type": "raw",
   "id": "eee7ec00",
   "metadata": {},
   "source": [
    "# Required directory structure before running this notebook\n",
    "\n",
    "|-ModelAnalysis.ipynb # THIS FILE\n",
    "|-LobeModel/\n",
    "  |-labels.txt\n",
    "  |-saved_model.pb\n",
    "  |-signature.json\n",
    "  |-variables/\n",
    "  |-example/\n",
    "|-MAIN\n",
    "  |-TEST1\n",
    "    |-LabelOne\n",
    "      |-Image001.jpg\n",
    "      |-Image00n.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the test datasets for the purpose of table & graph labelling (leave actual directory names the same)\n",
    "\n",
    "test_dataset_names = [\"Test1\",\"Test2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86993612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory variables\n",
    "\n",
    "# Directory containing 'saved_model.pb', 'labels.txt', 'signature.json' and 'variables' directory\n",
    "model_dir = os.path.join(os.getcwd(),\"LobeModel\")\n",
    "\n",
    "# Directory containing all image directories\n",
    "all_images_dir = os.path.join(os.getcwd(),\"MAIN\")\n",
    "\n",
    "# Directory containing the first set of test images\n",
    "test1_image_dir = os.path.join(all_images_dir,\"TEST1\")\n",
    "\n",
    "# Directory containing the optional second set of test images\n",
    "test2_image_dir = os.path.join(all_images_dir,\"TEST2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "\n",
    "def index_in_list(a_list, index):\n",
    "    return index < len(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b150dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is provided by Lobe.ai in the 'Example' folder when exporting a project to Python\n",
    "\n",
    "EXPORT_MODEL_VERSION = 1\n",
    "\n",
    "class TFModel:\n",
    "    def __init__(self, model_dir) -> None:\n",
    "        # make sure our exported SavedModel folder exists\n",
    "        self.model_dir = model_dir\n",
    "        with open(os.path.join(model_dir, \"signature.json\"), \"r\") as f:\n",
    "            self.signature = json.load(f)\n",
    "        self.model_file = os.path.join(self.model_dir, self.signature.get(\"filename\"))\n",
    "        # self.model_file = \"../\" + self.signature.get(\"filename\")\n",
    "        if not os.path.isfile(self.model_file):\n",
    "            raise FileNotFoundError(f\"Model file does not exist\")\n",
    "        self.inputs = self.signature.get(\"inputs\")\n",
    "        self.outputs = self.signature.get(\"outputs\")\n",
    "        # placeholder for the tensorflow session\n",
    "        self.session = None\n",
    "\n",
    "        # Look for the version in signature file.\n",
    "        # If it's not found or the doesn't match expected, print a message\n",
    "        version = self.signature.get(\"export_model_version\")\n",
    "        if version is None or version != EXPORT_MODEL_VERSION:\n",
    "            print(\n",
    "                f\"There has been a change to the model format. Please use a model with a signature 'export_model_version' that matches {EXPORT_MODEL_VERSION}.\"\n",
    "            )\n",
    "\n",
    "    def load(self) -> None:\n",
    "        self.cleanup()\n",
    "        # create a new tensorflow session\n",
    "        self.session = tf.compat.v1.Session(graph=tf.Graph())\n",
    "        # load our model into the session\n",
    "        tf.compat.v1.saved_model.loader.load(sess=self.session, tags=self.signature.get(\"tags\"), export_dir=self.model_dir)\n",
    "\n",
    "    def predict(self, image: Image.Image) -> dict:\n",
    "        # load the model if we don't have a session\n",
    "        if self.session is None:\n",
    "            self.load()\n",
    "\n",
    "        image = self.process_image(image, self.inputs.get(\"Image\").get(\"shape\"))\n",
    "        # create the feed dictionary that is the input to the model\n",
    "        # first, add our image to the dictionary (comes from our signature.json file)\n",
    "        feed_dict = {self.inputs[\"Image\"][\"name\"]: [image]}\n",
    "\n",
    "        # list the outputs we want from the model -- these come from our signature.json file\n",
    "        # since we are using dictionaries that could have different orders, make tuples of (key, name) to keep track for putting\n",
    "        # the results back together in a dictionary\n",
    "        fetches = [(key, output[\"name\"]) for key, output in self.outputs.items()]\n",
    "\n",
    "        # run the model! there will be as many outputs from session.run as you have in the fetches list\n",
    "        outputs = self.session.run(fetches=[name for _, name in fetches], feed_dict=feed_dict)\n",
    "        return self.process_output(fetches, outputs)\n",
    "\n",
    "    def process_image(self, image, input_shape) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given a PIL Image, center square crop and resize to fit the expected model input, and convert from [0,255] to [0,1] values.\n",
    "        \"\"\"\n",
    "        width, height = image.size\n",
    "        # ensure image type is compatible with model and convert if not\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        # center crop image (you can substitute any other method to make a square image, such as just resizing or padding edges with 0)\n",
    "        if width != height:\n",
    "            square_size = min(width, height)\n",
    "            left = (width - square_size) / 2\n",
    "            top = (height - square_size) / 2\n",
    "            right = (width + square_size) / 2\n",
    "            bottom = (height + square_size) / 2\n",
    "            # Crop the center of the image\n",
    "            image = image.crop((left, top, right, bottom))\n",
    "        # now the image is square, resize it to be the right shape for the model input\n",
    "        input_width, input_height = input_shape[1:3]\n",
    "        if image.width != input_width or image.height != input_height:\n",
    "            image = image.resize((input_width, input_height))\n",
    "\n",
    "        # make 0-1 float instead of 0-255 int (that PIL Image loads by default)\n",
    "        image = np.asarray(image) / 255.0\n",
    "        # format input as model expects\n",
    "        return image.astype(np.float32)\n",
    "\n",
    "    def process_output(self, fetches, outputs) -> dict:\n",
    "        # do a bit of postprocessing\n",
    "        out_keys = [\"label\", \"confidence\"]\n",
    "        results = {}\n",
    "        # since we actually ran on a batch of size 1, index out the items from the returned numpy arrays\n",
    "        for i, (key, _) in enumerate(fetches):\n",
    "            val = outputs[i].tolist()[0]\n",
    "            if isinstance(val, bytes):\n",
    "                val = val.decode()\n",
    "            results[key] = val\n",
    "        confs = results[\"Confidences\"]\n",
    "        labels = self.signature.get(\"classes\").get(\"Label\")\n",
    "        output = [dict(zip(out_keys, group)) for group in zip(labels, confs)]\n",
    "        sorted_output = {\"predictions\": sorted(output, key=lambda k: k[\"confidence\"], reverse=True)}\n",
    "        return sorted_output\n",
    "\n",
    "    def cleanup(self) -> None:\n",
    "        # close our tensorflow session if one exists\n",
    "        if self.session is not None:\n",
    "            self.session.close()\n",
    "            self.session = None\n",
    "\n",
    "    def __del__(self) -> None:\n",
    "        self.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcad853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runModel is used to classify the images in the TEST directory\n",
    "\n",
    "def runModel(test_image_dir, model, class_labels):\n",
    "    numiter = 0\n",
    "    testResults = {\"true\": [], \"predicted\": [], \"confidence\": []}\n",
    "    mislabelled = []\n",
    "    \n",
    "    classes = []\n",
    "    \n",
    "    for className in os.listdir(test_image_dir):\n",
    "        \n",
    "        classDir = os.path.join(test_image_dir, className)\n",
    "        if os.path.isdir(classDir) and not className.startswith('.'):\n",
    "            # Inside each folder\n",
    "            classes.append(className)\n",
    "\n",
    "            for imageName in os.listdir(classDir):\n",
    "                imageDir = os.path.join(classDir, imageName)\n",
    "                if os.path.isfile(imageDir) and not imageName.startswith('.'):\n",
    "                    # For each image\n",
    "\n",
    "                    image = Image.open(imageDir)\n",
    "                    outputs = model.predict(image)\n",
    "                    \n",
    "                    predicted_label = outputs[\"predictions\"][0][\"label\"]\n",
    "\n",
    "                    if predicted_label == classes[0]:\n",
    "                        confidence = outputs[\"predictions\"][0][\"confidence\"]\n",
    "                    else:\n",
    "                        confidence = outputs[\"predictions\"][1][\"confidence\"]\n",
    "\n",
    "                    testResults[\"true\"].append(class_labels[className.upper()])\n",
    "                    testResults[\"predicted\"].append(class_labels[predicted_label])\n",
    "                    testResults[\"confidence\"].append(confidence)\n",
    "                    \n",
    "                    if(class_labels[className.upper()] is not class_labels[predicted_label]):\n",
    "                        mislabelled.append({\"image\": imageName, \"predicted\": predicted_label,\"actual\": className.upper()})\n",
    "\n",
    "                    if numiter % 25 == 0 and numiter != 0:\n",
    "                        print(f\"{numiter} images processed.\")\n",
    "                    numiter += 1\n",
    "    print(f\"Finished! {numiter} images classified total.\")\n",
    "    return [testResults, mislabelled]\n",
    "\n",
    "\n",
    "# plotROC is used to display an ROC graph\n",
    "# Accepts multiple results: [[y_true, y_score, title], ...]\n",
    "\n",
    "def plotROC(data):\n",
    "    \n",
    "    plt.figure(figsize=(5,5), dpi=100)\n",
    "    for dataItem in data:\n",
    "        y_true = dataItem[0]\n",
    "        y_score = dataItem[1]\n",
    "        title = dataItem[2]\n",
    "        logistic_fpr, logistic_tpr, threshold = roc_curve(y_true, y_score)\n",
    "        auc_logistic = auc(logistic_fpr, logistic_tpr)\n",
    "        plt.plot(logistic_fpr, logistic_tpr, marker='.', label=f'{title} (auc = {round(auc_logistic,3)})')\n",
    "    \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(\"ROC\")\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "# printResults displays the accuracy score and classification report for a set of results\n",
    "    \n",
    "def printResults(results, title):\n",
    "    print(f\"{title}\\n\")\n",
    "    print(accuracy_score(results[\"true\"],results[\"predicted\"]))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(results[\"true\"],results[\"predicted\"]))   \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "# printMislabelled lists all of the incorrectly classified images in a dataset\n",
    "    \n",
    "def printMislabelled(mislabelledImages, title):\n",
    "    print(f\"{title}\\n\")\n",
    "    for mislabelledImage in mislabelledImages:\n",
    "        print(f\"{mislabelledImage['image']} was wrongly predicted to be {mislabelledImage['predicted']}\")\n",
    "    print(\"\\n\\n\")\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba9143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class labels for the data\n",
    "\n",
    "class_labels = {'NORMAL':0, 'ABNORMAL':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c3c8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the model using Lobe.ai's TFModel Class\n",
    "\n",
    "model = TFModel(model_dir=model_dir)\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6219c7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run model\n",
    "\n",
    "allTestResults = []\n",
    "allTestResultsProcessed = []\n",
    "\n",
    "for test_set in os.listdir(all_images_dir):\n",
    "    test_set_dir = os.path.join(all_images_dir, test_set)\n",
    "    if os.path.isdir(test_set_dir) and not test_set.startswith('.'):\n",
    "        # Inside each folder\n",
    "        testResult = runModel(test_set_dir, model, class_labels)\n",
    "        allTestResults.append(testResult)\n",
    "        allTestResultsProcessed.append([testResult[0][\"true\"],testResult[0][\"predicted\"],testResult[0][\"confidence\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d88c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Accuracy Tables\n",
    "\n",
    "for index, testResult in enumerate(allTestResults):\n",
    "    resultName = f\"Test {index + 1} Accuracy\"\n",
    "    if index_in_list(test_dataset_names, index):\n",
    "        resultName = f\"{test_dataset_names[index]} Accuracy\"\n",
    "    printResults(testResult[0], resultName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ee043b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ROC and AUC\n",
    "\n",
    "roc_data = []\n",
    "for index,testResult in enumerate(allTestResultsProcessed):\n",
    "    resultName = f\"Test {index} Dataset\"\n",
    "    if index_in_list(test_dataset_names, index):\n",
    "        resultName = f\"{test_dataset_names[index]} Dataset\"\n",
    "    roc_data.append([testResult[0],testResult[2],resultName])\n",
    "    \n",
    "plotROC(roc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc507dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,testResult in enumerate(allTestResults):\n",
    "    resultName = f\"Mislabelled Images from Test {index} Dataset:\"\n",
    "    if index_in_list(test_dataset_names, index):\n",
    "        resultName = f\"Mislabelled Images from {test_dataset_names[index]} Dataset:\"\n",
    "    printMislabelled(testResult[1], resultName)\n",
    "# printMislabelled(test1Mislabelled, f\"Mislabelled Images from {test1_dataset_name}\")\n",
    "# printMislabelled(test2Mislabelled, f\"Mislabelled Images from {test2_dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba88b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
